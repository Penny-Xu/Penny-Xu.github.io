{"data":{"markdownRemark":{"frontmatter":{"title":"When to use GPU for training?","date":"2019-09-04","tags":["PyTorch","CUDA"]},"html":"<p>This is going to be a super chill post. While at Peet's Coffee catching up with a friend and enjoying some cafe time, I noticed that his laptop had a nvidia gpu. So naturally, I asked wouldn't it be fun to run some deep learning training models on his laptop and see how it fares with running the same model on my laptop's cpu.</p>\n<h2>The Dataset</h2>\n<p>The training dataset is generated by <code>generate<em>disc</em>set</code> where a <code>train<em>input</code> sample is a random point (x, y) between [-1, 1] and <code>train</em>label</code> is either 0 or 1, which indicates if a sample input is within a 0.5pi radius circle centered around the origin. 1000 samples are generated to make up the training set.</p>\n<h2>Modifying code for gpu</h2>\n<p>Since I already have the training code in PyTorch that runs on my laptop, my friend will need to run the same training code, but just make sure that the gpu is used for computation. This is easily done when using PyTorch and Nvidia gpu.</p>\n<ul>\n<li>check if the gpu is available with <code>torch.cuda.is_available()</code></li>\n<li>get the gpu name just to make sure with <code>torch.cuda.get<em>device</em>name(0)</code></li>\n<li>port model and train dataset tensors to gpu before train loop with <code>.cuda()</code></li>\n</ul>\n<h2>The model</h2>\n<p>I used a simple linear model with Relu activations for this task. I tested the runtime with increasing number of hidden layers, with doubling the number of nerons in each new layer than the previous. So the number of parameters for each model increased exponentially.</p>\n<h2>The result</h2>\n<p><span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 750px;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 60.836501901140686%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAd9USD//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAaEAACAgMAAAAAAAAAAAAAAAAAARAhMVFx/9oACAEBAAE/IZfS9iwf/9oADAMBAAIAAwAAABDjD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAQACAQUAAAAAAAAAAAAAAAEAETEQIUFRkf/aAAgBAQABPxAxo2uzLC0jyXbLL1DZXkn/2Q=='); background-size: cover; display: block;\"\n    ></span>\n    <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;\"\n        alt=\"chart\"\n        title=\"\"\n        src=\"/static/b716f572acba8c6c148967ba67257f53/a66cd/chart.jpg\"\n        srcset=\"/static/b716f572acba8c6c148967ba67257f53/4272c/chart.jpg 188w,\n/static/b716f572acba8c6c148967ba67257f53/1459e/chart.jpg 375w,\n/static/b716f572acba8c6c148967ba67257f53/a66cd/chart.jpg 750w,\n/static/b716f572acba8c6c148967ba67257f53/0cd83/chart.jpg 1052w\"\n        sizes=\"(max-width: 750px) 100vw, 750px\"\n      />\n  </span></p>"}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"when-gpu"}}
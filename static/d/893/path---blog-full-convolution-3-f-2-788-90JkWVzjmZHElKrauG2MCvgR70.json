{"data":{"markdownRemark":{"frontmatter":{"title":"Fully Convolutional Networks","date":"06-16-2019"},"html":"<p>Did you know that all fully connected layers in neural networks can be replaced with convolutional layers? This means that networks that first applies convolutional layers, and then applies fully connected linear layers, can be made fully convolutional. Or in other words, a MLP can be represented by convolution layers only.</p>\n<p>Now this was news to me because I always thought linear layers and convolutional layers to be different, with different input types, weights, and outputs, as well as the idea that convolution is meant to do feature extraction, while fully connected layers is meant to do classification.</p>\n<p>However, linear and convolutional layers are almost identical functionally as both layers simply computes dot products. The only difference is that the neurons in the convolution layers are connected to a local region and that parameters may be shared. Therefore, it is very easy to convert fully connected layers to convolutional layers.</p>\n<p>Let's see how this conversion is done. Let's say that we have an architecture consists of first convolutional layers and then fully connected layers. Let's say that in the forward pass, the output of the convolutional layers is a tensor of shape <strong>H x W x C</strong>, where H indicates height, W indicates width, and C indicates number of channels or the number of feature maps. If we want our next layer to be fully connected with a size of <strong>3</strong>, then this layer can be replaced by a convolution layer with <strong>filter = C x H x W, Padding = 0, stride = 1, output channel = 3.</strong> In other words, we are setting the filter size to be exactly the size of the input volume. Each filter contributes to exactly <strong>one</strong> output and that there are 3 filters total to produce an output of <strong>1 x 1 x 3</strong>.</p>\n<p>Now let's visualize how these two layers produces the same outputs. Let's say that the input to the layers is a tensor of H x W x C, where H = 2, W = 2, and C = 3.</p>\n<h2>Fully Connected Layer</h2>\n<p><img src=\"/line-709b7dd2c0ed5442ff5242050f3eb2b6.gif\"></p>\n<p>In the fully connected layer case, the input is first flattened to a tensor of size 12. The yellow, blue, and pink tensors represent the weights, each of size H * W * C, where through the dot product plus some bias produces a final output of 3 neurons.</p>\n<h2>Convolution Layer</h2>\n<p><img src=\"/conv-66500ecf6af31953e382e08be95e3b33.gif\">\nIn the convolution layer case, the yellow, blue and pink tensors represent the filters, each of size H x W x C. A single neuron is produced by convolution. Since there is no sliding of the filters, this convolution operation is essentially the dot product, just like in the fully connected layer case. Since there are 3 filters, 3 neurons are produced.</p>\n<h2>Example</h2>\n<p>Let's take the AlexNet for example, where the last three layers are linear. The input to the first linear layers is <strong>6 x 6 x 256</strong>. Let's convert the three linear layers in the original to convolutions. Keep in mind the conv2d notation is conv2d(in_channel, out_channel, kernel_size = (a,b)). Also, a kernel is <strong>one</strong> channel of a filter. So the filter here defined by the conv2d(in_channel, out_channel, kernel_size = (a,b)) has <strong>filter size</strong> of kernel_size * in_channel.</p>\n<pre><code>Original:                       Converted:                                   \n\n    convolution layers...           convolution layers...\n\n    1. dropout                      1. dropout\n    2. linear (9216 -> 4096)        2. conv2d(256, 4096, kernel_size = (6,6))\n    3. relu                         3. reLU\n    4. dropout                      4. dropout\n    5. linear (4096 -> 4096)        5. conv2d(4096, 4096, kernel_size = (1,1))\n    6. relu                         6. relu\n    7. linear (4096 -> 1000)        7. conv2d(4096, 1000, kernel_size = (1,1))\n</code></pre>\n<h2>Why convert to convolution?</h2>\n<p>So now that you know how to convert linear layers to convolutional layers, you are probably asking why do people do it if in terms of functionality they are the same. Well, this conversion to convolution does not change anything if the input size is such that the output has a single spatial cell, which is in the example above as the input was 6 x 6 x 256, and then convolution filter is 6 x 6 x 256. but it fully re-uses computation to\nget a prediction at multiple locations when the input is larger</p>"}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"full-convolution"}}
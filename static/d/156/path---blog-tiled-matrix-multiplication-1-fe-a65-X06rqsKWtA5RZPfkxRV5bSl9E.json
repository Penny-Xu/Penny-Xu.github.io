{"data":{"markdownRemark":{"frontmatter":{"title":"Tiled matrix multiplication","date":"2019-08-24","tags":["deep learning","matrix multiplication","CUDA"]},"html":"<p>Let's talk about tiled matrix multiplication today. This is an algorithm performed on GPUs due to the parallel nature of matrix multiplication. We will especially look at a method called \"tiling,\" which is used to take advantage of the shared memory on the GPU. We will then examine the CUDA kernel code that do exactly what we see in the visualization, which shows what each thread within a block is doing to compute the output.</p>\n<h2>Why do you care?</h2>\n<p>The efficiency of calculating matrix multiplication is the backbone of everything. Everything as in rendering graphics and machine learning. Ever heard of Tensors? Yeah...everything is matrix multiplication I swear.</p>\n<h2>Some background</h2>\n<ul>\n<li>Grid</li>\n<li>Block</li>\n<li>Thread</li>\n</ul>\n<p><img src=\"/tmm-59dd890f48435e692c47919d0df4a5e6.gif\"></p>\n<h2>Kernel code</h2>"}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"tiled-matrix-multiplication"}}
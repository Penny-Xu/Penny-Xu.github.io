{"data":{"markdownRemark":{"frontmatter":{"title":"Convolution is Matrix Multiplication","date":"2019-11-18","tags":["neural network","deep learning","parallelism","convolution","matrix multiplication"]},"html":"<h2>Initial Thoughts</h2>\n<p>The computation pattern in training a convolutional network is very similar to matrix multiplication: it is both compute intensive and highly parallel.</p>\n<p>convolution == 2d dot product == unrolled 1d dot product == matrix multiplication</p>\n<p>it is pretty fun to think about, that everything we know in life decomposes to matrix multiplication, which we discussed in an earlier post (matrix multiplication is parallel) .. it is just lucky to have an official name. Now thinking about it - convolution is just a 2d dot product - can we all have a vote to call convolution matrix dot product? If we call an operation between two matrices that does a <strong>multiplication followed by summation</strong> through collapsing one dimension <strong>matrix \"multiplication\"</strong> - we should really call an operation between two matrices that does a <strong>dot product followed by summation</strong> through collapsing one dimension <strong>matrix \"dot product\"</strong> - it's only fair?!</p>\n<h2>Example</h2>\n<p>The central idea is unfolding and duplicating of the inputs to the convolutional kernel in such way that all elements needed to compute one output element will be stored as one sequential block.</p>"}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"convolution-is-matrixmultiplication"}}
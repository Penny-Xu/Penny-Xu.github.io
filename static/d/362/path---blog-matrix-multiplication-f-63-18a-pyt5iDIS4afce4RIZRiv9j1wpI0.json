{"data":{"markdownRemark":{"frontmatter":{"title":"Matrix Multiplication is Parallel","date":"06-17-2019"},"html":"<p>Everyone knows how to compute matrix multiplication. But what are we exactly doing with this operation? I want to introduce my way of viewing matrix multiplication, a way that is intuitively parallel.</p>\n<p>I was introduced to this view of matrix multiplication, inadvertently, when I was writing a backwards pass for a deep learning model. If you have ever written one from scratch, you might understand the amount of reshape, transpose, and summing necessary to manipulate the tensors so that the dimensions match. At first, I was able to get one sample, a 1d feature vector, to work with the backwards pass to calculate the change in gradients, a tensor. After that, I started to implement mini batch gradient decent, which means that the operations done on each sample of the mini batch are the same, but I just had to sum up all the tensors produced by each sample to find the total change in gradients produced by each mini batch. I knew at that point that I can simply use a for loop to sum up the resulting tensors from each sample, but I thought there must be a better way... If you have no idea what I am talking talk, don't worry because it is not important. It is just my reflection of how I got that \"ah-ha\" moment!</p>\n<p>Let's say we have two matrices that we want to multiply together:</p>\n<pre><code>  Matrix A (2x3):            Matrix B (3x2):\n\n    1  2  3                       7  10\n    4  5  6                       8  11\n                                  9  12\n</code></pre>\n<h2>Most people's view:</h2>\n<p><img src=\"/download-2b7512fc61647d4f56aa1133436eecdf.gif\">\nSo I am sure that if you are reading this, you know that in order to compute A x B, let's say matrix C, we take the each row of A and each column of B and compute the dot product to get the resulting matrix.</p>\n<pre><code>    Matrix C (2x2):\n\n    1 * 7 + 2 * 8 + 3 * 9 = 50        1 * 10 + 2 * 11 + 3 * 12 = 68\n    4 * 7 + 5 * 8 + 6 * 9 = 122       4 * 10 + 5 * 11 + 6 * 12 = 167\n\n    50   68\n    122  167\n</code></pre>\n<h2>My view:</h2>\n<p>Le't transpose matrix A such that A and B has the same number of rows.</p>\n<pre><code>  Matrix A (2x3):            Matrix B (3x2):\n\n    1  4                         7  10\n    2  5                         8  11\n    3  6                         9  12\n</code></pre>\n<p>For every row, a 2x2 matrix is created through matrix multiplication. Since each row is a 1x2 vector, we transpose each row from A to get 2x1. So each row from A (2x1) multiply each row from B (1x2) creates a 2x2 matrix.</p>\n<pre><code>Row 1:  7   10\n        28  40\n\nRow 2:  16  22\n        40  55\n\nRow 3:  27  36\n        54  72\n</code></pre>\n<p>Now we can collapse the three matrices into one matrix, by summing up component-wise through each row.</p>\n<p><img src=\"/way2-6eb01f28895d07a79599530b927a5d9f.gif\"></p>\n<h2>My thoughts:</h2>"}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"matrix-multiplication"}}
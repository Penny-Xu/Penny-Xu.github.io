{"data":{"markdownRemark":{"frontmatter":{"title":"Fully Convolutional Networks","date":"06-16-2019"},"html":"<p>Did you know that all fully connected layers in neural networks can be replaced with convolutional layers? This means that networks that first applies convolutional layers, and then applies fully connected linear layers, can be made fully convolutional. Or in other words, a MLP can be represented by convolution layers only.</p>\n<p>Now this was news to me because I always thought linear layers and convolutional layers to be different, with different input types, weights, and outputs, as well as the idea that convolution is meant to do feature extraction, while fully connected layers is meant to do classification.</p>\n<p>However, linear and convolutional layers are almost identical functionally as both layers simply computes dot products. The only difference is that the neurons in the convolution layers are connected to a local region and that parameters may be shared. Therefore, it is very easy to convert fully connected layers to convolutional layers.</p>\n<p>Let's see how this conversion is done. Let's say that we have an architecture consists of first convolutional layers and then fully connected layers. Let's say that in the forward pass, the output of the convolutional layers is a tensor of shape <strong>C x H x W</strong>, where C indicates number of channels, H indicates height, and W indicates width. If we want our next layer to be fully connected with a size of <strong>3</strong>, then this layer can be replaced by a convolution layer with <strong>filter = H x W, Padding = 0, stride = 1, output channel = 3.</strong> </p>\n<h2>Fully Connected Layer</h2>\n<p><img src=\"/line-709b7dd2c0ed5442ff5242050f3eb2b6.gif\"></p>\n<h2>Convolution Layer</h2>\n<p><img src=\"/conv-66500ecf6af31953e382e08be95e3b33.gif\"></p>\n<h2>Why is it useful?</h2>"}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"full-convolution"}}
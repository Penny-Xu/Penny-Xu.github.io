{"data":{"markdownRemark":{"frontmatter":{"title":"Fully Convolutional Networks","date":"06-16-2019"},"html":"<p>Did you know that all fully connected layers in neural networks can be replaced with convolutional layers? This means that networks that first applies convolutional layers, and then applies fully connected linear layers, can be made fully convolutional. Or in other words, a MLP can be represented by convolution layers only.</p>\n<p>Now this was news to me because I always thought linear layers and convolutional layers to be different, with different input types, weights, and outputs, as well as the idea that convolution is meant to do feature extraction, while fully connected layers is meant to do classification.</p>\n<p>However, linear and convolutional layers are almost identical functionally as both layers simply computes dot products. The only difference is that the neurons in the convolution layers are connected to a local region and that parameters may be shared. Therefore, it is very easy to convert fully connected layers to convolutional layers.</p>\n<p>Let's see how this conversion is done. Let's say that we have an architecture consists of first convolutional layers and then fully connected layers. Let's say that in the forward pass, the output of the convolutional layers is a tensor of shape <strong>H x W x C</strong>, where H indicates height, W indicates width, and C indicates number of channels. If we want our next layer to be fully connected with a size of <strong>3</strong>, then this layer can be replaced by a convolution layer with <strong>filter = C x H x W, Padding = 0, stride = 1, output channel = 3.</strong> In other words, we are setting the filter size to be exactly the size of the input volume. Each filter contributes to exactly <strong>one</strong> output and that there are 3 filters total to produce an output of <strong>1 x 1 x 3</strong>.</p>\n<p>Now let's visualize how these two layers produces the same outputs. Let's say that the output of the convolution is H x W x C, where H = 2, W = 2, and C = 3.</p>\n<h2>Fully Connected Layer</h2>\n<p><img src=\"/line-709b7dd2c0ed5442ff5242050f3eb2b6.gif\"></p>\n<p>In the fully connected layer case, the input is </p>\n<h2>Convolution Layer</h2>\n<p><img src=\"/conv-66500ecf6af31953e382e08be95e3b33.gif\"></p>\n<h2>Why is it useful?</h2>"}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"full-convolution"}}